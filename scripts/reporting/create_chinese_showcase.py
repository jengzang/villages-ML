#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ›å»ºä¸­æ–‡åˆ†æžç»“æžœå±•ç¤ºæ–‡æ¡£
"""

import json

# Load the extracted data
with open('docs/analysis_results_data.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# Create the Chinese showcase document
content = """# å¹¿ä¸œçœè‡ªç„¶æ‘å‘½åè§„å¾‹åˆ†æžç»“æžœå±•ç¤º

> æœ¬æ–‡æ¡£å±•ç¤ºåŸºäºŽ285,860ä¸ªè‡ªç„¶æ‘åçš„å®žé™…åˆ†æžå‘çŽ°å’Œæ´žå¯Ÿ

## ðŸ“Š æ•°æ®æ¦‚è§ˆ

- **æ€»æ‘æ•°**: {total_villages:,}ä¸ªè‡ªç„¶æ‘
- **æœ‰æ•ˆæ‘æ•°**: {valid_villages:,}ä¸ªï¼ˆ{valid_pct:.1f}%ï¼‰
- **è¦†ç›–èŒƒå›´**: å¹¿ä¸œçœå…¨å¢ƒ
  - 21ä¸ªåœ°çº§å¸‚
  - 100+ä¸ªåŒºåŽ¿
  - 1,500+ä¸ªä¹¡é•‡

---

## é˜¶æ®µ0ï¼šæ•°æ®é¢„å¤„ç†ä¸Žå‰ç¼€æ¸…ç†

### æ ¸å¿ƒå‘çŽ°

**å‰ç¼€æ¸…ç†ç»Ÿè®¡**ï¼š
- åŽ»é™¤å‰ç¼€çš„æ‘åï¼š{preprocessed_count:,}ä¸ªï¼ˆ{preprocessed_pct:.1f}%ï¼‰
- ä¸»è¦å‰ç¼€ç±»åž‹ï¼š
  - è¡Œæ”¿æ‘åå‰ç¼€ï¼ˆå¦‚"XXæ‘å§”ä¼š"ï¼‰
  - æ–¹ä½è¯å‰ç¼€ï¼ˆå¦‚"ä¸œ"ã€"è¥¿"ã€"å—"ã€"åŒ—"ï¼‰
  - å¤§å°è¯å‰ç¼€ï¼ˆå¦‚"å¤§"ã€"å°"ï¼‰

### æ„ä¹‰

å‰ç¼€æ¸…ç†ç¡®ä¿äº†åŽç»­åˆ†æžèšç„¦äºŽè‡ªç„¶æ‘çš„æœ¬è´¨å‘½åç‰¹å¾ï¼Œè€Œéžè¡Œæ”¿ç®¡ç†å±‚é¢çš„é™„åŠ ä¿¡æ¯ã€‚

---

## é˜¶æ®µ1-3ï¼šå­—ç¬¦é¢‘çŽ‡ä¸ŽåŒºåŸŸå€¾å‘æ€§åˆ†æž

### å…¨å±€é«˜é¢‘å­—ç¬¦ Top 20

| æŽ’å | å­—ç¬¦ | é¢‘çŽ‡ | å‡ºçŽ°æ‘æ•° | è¯­ä¹‰ç±»åˆ« |
|------|------|------|----------|----------|
""".format(
    total_villages=data['overview']['total_villages'],
    valid_villages=data['overview']['valid_villages'],
    valid_pct=data['overview']['valid_villages'] / data['overview']['total_villages'] * 100,
    preprocessed_count=data['overview']['preprocessed_count'],
    preprocessed_pct=data['overview']['preprocessed_count'] / data['overview']['total_villages'] * 100
)

# Add top characters
for i, char_data in enumerate(data['global_top_chars'], 1):
    content += f"| {i} | {char_data['char']} | {char_data['frequency']*100:.2f}% | {char_data['village_count']:,} | - |\n"

content += """
### æ ¸å¿ƒæ´žå¯Ÿ

1. **åœ°å½¢åœ°è²Œä¸»å¯¼**ï¼šå‰20ä¸ªé«˜é¢‘å­—ä¸­ï¼Œåœ°å½¢ç›¸å…³å­—ç¬¦å 40%ï¼ˆå‘ã€å±±ã€å²­ã€åªã€å²—ç­‰ï¼‰
2. **æ°´ç³»ç‰¹å¾æ˜¾è‘—**ï¼šå¡˜ã€æ°´ç­‰æ°´ç³»å­—ç¬¦é«˜é¢‘ï¼Œåæ˜ å¹¿ä¸œæ°´ç½‘å¯†é›†çš„åœ°ç†ç‰¹å¾
3. **æ–¹ä½è¯æ™®é**ï¼šä¸Šã€ä¸‹ã€å¤´ã€è§’ç­‰æ–¹ä½/ä½ç½®è¯å 20%ï¼Œä½“çŽ°ç›¸å¯¹å®šä½çš„å‘½åä¹ æƒ¯
4. **èšè½ç±»åž‹æ˜Žç¡®**ï¼šæ‘ã€å±‹ã€å›´ç­‰èšè½ç±»åž‹å­—ç¬¦é¢‘çŽ‡æžé«˜

---

## åŒºåŸŸå€¾å‘æ€§åˆ†æžï¼šå„åŸŽå¸‚å‘½åç‰¹å¾

"""

# Add regional tendency for each city
for city, city_data in data['regional_tendency'].items():
    content += f"### {city}\n\n"
    content += "**é«˜å€¾å‘å­—ç¬¦**ï¼ˆæŒ‰å€¾å‘å€¼æŽ’åºï¼‰ï¼š\n\n"
    content += "| å­—ç¬¦ | å€¾å‘å€¼(lift) | åŒºåŸŸé¢‘çŽ‡ | Z-score |\n"
    content += "|------|--------------|----------|----------|\n"

    for char_data in city_data[:10]:
        content += f"| {char_data['char']} | {char_data['lift']:.2f} | {char_data['frequency']*100:.2f}% | {char_data['z_score']:.2f} |\n"

    content += "\n"

content += """
---

## é˜¶æ®µ4ï¼šå­—ç¬¦è¯­ä¹‰ç›¸ä¼¼æ€§åˆ†æž

### æ ¸å¿ƒå‘çŽ°

é€šè¿‡Word2Vecå­—ç¬¦åµŒå…¥ï¼ˆ100ç»´å‘é‡ï¼‰ï¼Œå‘çŽ°äº†å­—ç¬¦ä¹‹é—´çš„è¯­ä¹‰èšç±»æ¨¡å¼ï¼š

"""

# Add character similarity
for char, sim_data in data['char_similarity'].items():
    content += f'**"{char}"çš„ç›¸ä¼¼å­—ç¬¦**ï¼š\n'
    similar_chars = [f"{d['similar_char']} ({d['cosine_similarity']:.2f})" for d in sim_data[:10]]
    content += "- " + "ã€".join(similar_chars) + "\n\n"

content += """
### æ´žå¯Ÿ

1. **åœ°å½¢å­—èšç±»æ˜Žæ˜¾**ï¼šå±±åœ°åœ°å½¢å­—ï¼ˆå±±ã€å²­ã€å²—ã€å‘ã€å¡ï¼‰å½¢æˆç´§å¯†çš„è¯­ä¹‰ç°‡
2. **æ°´ç³»å­—é«˜åº¦ç›¸å…³**ï¼šæ°´ç³»å­—ç¬¦ï¼ˆæ°´ã€æ²³ã€æ±Ÿã€æºªã€æ¶Œï¼‰ç›¸ä¼¼åº¦æžé«˜
3. **èšè½ç±»åž‹å­—äº’é€š**ï¼šæ‘ã€å±‹ã€å¯¨ã€å›´ç­‰èšè½ç±»åž‹å­—ç›¸ä¼¼åº¦é«˜ï¼Œè¯´æ˜Žå®ƒä»¬åœ¨å‘½åä¸­å¯äº’æ¢ä½¿ç”¨

---

## é˜¶æ®µ5-7ï¼šèšç±»åˆ†æž

### èšç±»ç»“æžœ

| ç®—æ³• | èšç±»æ•°(k) | Silhouette Score | Davies-Bouldin Index |
|------|-----------|------------------|----------------------|
"""

# Add clustering metrics
for metric in data['clustering_metrics'][:10]:
    k_val = metric.get('k', '-')
    content += f"| {metric['algorithm']} | {k_val} | {metric['silhouette_score']:.3f} | {metric['davies_bouldin_index']:.3f} |\n"

content += """
### èšç±»å¤§å°åˆ†å¸ƒ

"""

# Add cluster sizes
if data['cluster_sizes']:
    content += "| èšç±»ID | æ‘è½æ•°é‡ |\n"
    content += "|--------|----------|\n"
    for cluster in data['cluster_sizes']:
        content += f"| {cluster['cluster_id']} | {cluster['village_count']:,} |\n"

content += """
---

## é˜¶æ®µ8-10ï¼šç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æž

### é«˜æ˜¾è‘—æ€§å­—ç¬¦ï¼ˆZ-score > 10, p < 0.001ï¼‰

| åŸŽå¸‚ | å­—ç¬¦ | Z-score | å€¾å‘å€¼(lift) |
|------|------|---------|--------------|
"""

# Add high significance characters
for sig_data in data['high_significance'][:20]:
    content += f"| {sig_data['region_name']} | {sig_data['char']} | {sig_data['z_score']:.2f} | {sig_data['lift']:.2f} |\n"

content += """
---

## æ€»ä½“æ´žå¯Ÿä¸Žåº”ç”¨ä»·å€¼

### ä¸»è¦å‘çŽ°

1. **åœ°ç†çŽ¯å¢ƒæ˜¯å‘½åçš„é¦–è¦å› ç´ **
   - å±±åœ°åœ°åŒºï¼šåã€å¶‚ã€åªã€å¾„ã€å‘
   - æ°´ç½‘åœ°åŒºï¼šå›´ã€æ¶Œã€å¡˜ã€æ¸¯
   - å¹³åŽŸåœ°åŒºï¼šåŸ”ã€åªã€ç”°

2. **æ–‡åŒ–åœˆè¾¹ç•Œæ¸…æ™°**
   - å¹¿åºœæ–‡åŒ–åœˆï¼šå›´ã€æ¶Œã€åŠ
   - æ½®æ±•æ–‡åŒ–åœˆï¼šå¯¨ã€åŽã€åŸ”
   - å®¢å®¶æ–‡åŒ–åœˆï¼šåã€å¶‚ã€åª

3. **æ–¹è¨€å½±å“æ·±è¿œ**
   - é—½å—è¯­ç³»ï¼šåŽã€ç¤¾
   - å®¢å®¶è¯ï¼šåã€å¶‚
   - ç²¤è¥¿æ–¹è¨€ï¼šä»”ã€å¯®

### åº”ç”¨ä»·å€¼

**1. åœ°åå­¦ç ”ç©¶**
- æä¾›äº†å¤§è§„æ¨¡åœ°åæ•°æ®çš„ç»Ÿè®¡åˆ†æžæ–¹æ³•
- æ­ç¤ºäº†åœ°åå‘½åçš„ç³»ç»Ÿæ€§è§„å¾‹

**2. æ–¹è¨€åœ°ç†å­¦**
- é€šè¿‡åœ°ååˆ†æžæ–¹è¨€åˆ†å¸ƒè¾¹ç•Œ
- è¯†åˆ«æ–¹è¨€ç‰¹å¾è¯æ±‡

**3. æ–‡åŒ–åœ°ç†å­¦**
- é‡åŒ–æ–‡åŒ–åœˆè¾¹ç•Œ
- ç ”ç©¶æ–‡åŒ–ä¼ æ’­ä¸Žæ‰©æ•£

**4. åŽ†å²åœ°ç†å­¦**
- è¿½æº¯åŽ†å²è¿å¾™è·¯çº¿
- ç ”ç©¶èšè½å½¢æˆä¸Žæ¼”å˜

---

**æ–‡æ¡£ç”Ÿæˆæ—¶é—´**ï¼š2026-02-19
**æ•°æ®ç‰ˆæœ¬**ï¼šåŸºäºŽé¢„å¤„ç†è¡¨ï¼ˆåŽ»å‰ç¼€åŽï¼‰
**åˆ†æžé˜¶æ®µ**ï¼šPhase 0-14
"""

# Write to file
output_file = 'docs/åˆ†æžç»“æžœå±•ç¤º_ä¸­æ–‡ç‰ˆ.md'
with open(output_file, 'w', encoding='utf-8') as f:
    f.write(content)

print(f"[OK] ä¸­æ–‡å±•ç¤ºæ–‡æ¡£å·²åˆ›å»º: {output_file}")
print(f"[OK] æ–‡æ¡£é•¿åº¦: {len(content)} å­—ç¬¦")
